{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd155408",
   "metadata": {},
   "source": [
    "# <center> Deep Learning Project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954f1cd",
   "metadata": {},
   "source": [
    "> - __Ahmed Abdelazeem__ (m20210433)\n",
    "> - __Omar Jarir__ (m20201378)  \n",
    "> - __Chung-Ting Huang__ (m20210437) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bfc00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a8114",
   "metadata": {},
   "source": [
    "- __The objective of this notebook is to perform hyperparameters tuning:__\n",
    "- Some references:\n",
    "   - https://neptune.ai/blog/keras-tuner-tuning-hyperparameters-deep-learning-model/amp\n",
    "   - https://keras.io/guides/keras_tuner/getting_started/\n",
    "   - https://keras.io/api/utils/serialization_utils/\n",
    "   - https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "   - https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fcad8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "                # !pip install keras-tuner --upgrade\n",
    "# !pip install -q -U keras-tuner\n",
    "#!pip install findspark\n",
    "#!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3facbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd1018",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3f3c4",
   "metadata": {},
   "source": [
    "- __Importing the necessary libraries ðŸ“š:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7afd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as python_random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import keras_tuner as kt\n",
    "import keras.backend as K\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be2fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau \n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52987b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b710363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEED = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6defba",
   "metadata": {},
   "source": [
    "Fixing the random number seed to ensure that the results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b17cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session = K.get_session()\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "python_random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c1d56c",
   "metadata": {},
   "source": [
    "- __Helper functions:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a0c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to create dataframe with metrics\n",
    "\n",
    "def performanceMetricsDF(metricsObj, yTrain, yPredTrain, yTest, yPredTest):\n",
    "    measures_list = ['ACCURACY','PRECISION', 'RECALL','F1 SCORE','AUC']\n",
    "    train_results = [metricsObj.accuracy_score(yTrain, yPredTrain),\n",
    "                metricsObj.precision_score(yTrain, yPredTrain),\n",
    "                metricsObj.recall_score(yTrain, yPredTrain, average='macro'),\n",
    "                metricsObj.f1_score(yTrain, yPredTrain, average='macro'),\n",
    "                metricsObj.roc_auc_score(yTrain, yPredTrain),    \n",
    "                ]\n",
    "    test_results = [metricsObj.accuracy_score(yTest, yPredTest),\n",
    "               metricsObj.precision_score(yTest, yPredTest),\n",
    "               metricsObj.recall_score(yTest, yPredTest, average='macro'),\n",
    "               metricsObj.f1_score(yTest, yPredTest, average='macro'),\n",
    "               metricsObj.roc_auc_score(yTest, yPredTest), \n",
    "               ]\n",
    "    resultsDF = pd.DataFrame({'Measure': measures_list, 'Train': train_results, 'Test':test_results}, index=measures_list)\n",
    "    return resultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221a8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix - Adapted from https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(cf,annot=box_labels, fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09be78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to find outliers on columns based on percentile\n",
    "def removeOutliers(df, colList, lowPercentile=0.05, highPercentile=0.95, verbose=False):\n",
    "    quant_df = df[colList].quantile([lowPercentile, highPercentile])\n",
    "    if verbose:\n",
    "        print(quant_df)\n",
    "    for name in list(df[colList].columns):\n",
    "        df = df[(df[name] >= quant_df.loc[lowPercentile, name]) & (df[name] <= quant_df.loc[highPercentile, name])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a200cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MutualInfoScores(X, y):    \n",
    "    mi = pd.Series(mutual_info_classif(X, y))\n",
    "    mi /= mi.max()\n",
    "    mi.index = X.columns\n",
    "    mi.sort_values(ascending=False).plot.bar(figsize=(20, 6))\n",
    "    plt.title(\"Feature univariate score\")\n",
    "    plt.ylabel('Mutual Information')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FTestScores(X, y):\n",
    "    f_scores = pd.Series(-np.log10(f_classif(X, y)[1]))\n",
    "    f_scores /= f_scores.max()\n",
    "    f_scores.index = X.columns\n",
    "    f_scores.sort_values(ascending=False).plot.bar(figsize=(20,6))\n",
    "    plt.title(\"Feature univariate score\")\n",
    "    plt.ylabel(r\"Univariate score ($-Log(p_{value})$)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71b09e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c87322",
   "metadata": {},
   "source": [
    "- __Loading the dataset:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c93f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds= pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589e519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63537575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the shape of the dataset:\n",
    "\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that our dataset does not contain any duplicates.\n",
    "\n",
    "ds.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba58569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the type of the columns:\n",
    "\n",
    "ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37900e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the target distribution is imbalanced.\n",
    "\n",
    "sns.countplot(y='Bankrupt?', data = ds, palette='viridis', orient = 'h');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcda901",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"Bankrupt?\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MutualInfoScores(ds.drop(columns=\"Bankrupt?\"), ds[\"Bankrupt?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.copy(deep=True)\n",
    "\n",
    "y = X[\"Bankrupt?\"]\n",
    "X = X.drop(columns=[\"Bankrupt?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa52fc",
   "metadata": {},
   "source": [
    "### Splitting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset intro train and test sets.\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.3,\n",
    "                                   shuffle =True, stratify=y, random_state=SEED)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.3,\n",
    "                                                   shuffle = True, stratify=y_train, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e4be6",
   "metadata": {},
   "source": [
    "### Dealing with outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94570b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = removeOutliers(x_train, colList=x_train.columns , lowPercentile=0.01, highPercentile=0.99, verbose=False)\n",
    "# x_val = removeOutliers(x_val, colList=x_val.columns , lowPercentile=0.01, highPercentile=0.99, verbose=False)\n",
    "# x_test = removeOutliers(x_test, colList=x_test.columns , lowPercentile=0.01, highPercentile=0.99, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81489080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96310f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector = SelectKBest(f_classif, k=4)\n",
    "# selector.fit(X_train, y_train)\n",
    "# scores = -np.log10(selector.pvalues_)\n",
    "# scores /= scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "MutualInfoScores(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FTestScores(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d42fb",
   "metadata": {},
   "source": [
    "- The figure above shows that the number of features to select is equal to 24,because they have a value superior than 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MutualInfoScores(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce876a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=15)\n",
    "\n",
    "# selecting the features:\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "kept_columns = list(x_train.columns[selector.get_support()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694264de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[kept_columns]\n",
    "x_val = x_val[kept_columns]\n",
    "x_test = x_test[kept_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66007a",
   "metadata": {},
   "source": [
    "# Data Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ds.copy(deep=True)\n",
    "\n",
    "# y = X[\"Bankrupt?\"]\n",
    "# X = X.drop(columns=[\"Bankrupt?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34c042",
   "metadata": {},
   "source": [
    "## Data Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199499da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We use the standard scaler in order to normalize the data:\n",
    "\n",
    "scaler = StandardScaler() \n",
    "x_train = scaler.fit_transform(x_train) \n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a94ca7",
   "metadata": {},
   "source": [
    "# Hyper parameters tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5e6de",
   "metadata": {},
   "source": [
    "__Using Keras tuner:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassWeights = dict(enumerate(class_weight.compute_class_weight('balanced', \n",
    "                            classes=np.unique(y_train), y=y_train)))\n",
    "ClassWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ce45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop = EarlyStopping(monitor='val_f1', patience=3, verbose=0)\n",
    "\n",
    "CallBacksList = [EarlyStop,]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17149fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "\n",
    "    def build(self ,hp):\n",
    "\n",
    "        hp_units_1 = hp.Choice(\"Layer 1\", [64, 128, 256])\n",
    "        hp_units_2 = hp.Choice(\"Layer 2\", [16, 32]) # 64\n",
    "        hp_units_3 = hp.Choice(\"Layer 3\", [4, 8, 16]) # 32, 64, 16 \n",
    "        hp_activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        hp_kernel_initializer = hp.Choice(\"kernel_initializer\", [\"glorot_uniform\", \"glorot_normal\"])\n",
    "        hp_learning_rate = hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"log\", default=1e-3)  \n",
    "        hp_loss = hp.Choice(\"loss_type\", [\"BC\", \"FL\"])\n",
    "        hp_gamma = hp.Choice(\"Gamma\", [0.0, 0.5, 1.0, 2.0])\n",
    "        \n",
    "        model = Sequential()\n",
    "    \n",
    "        model.add(layers.Dense(units = hp_units_1,\n",
    "                        kernel_initializer = hp_kernel_initializer,\n",
    "                        kernel_regularizer = tf.keras.regularizers.L2(0.1),\n",
    "                        activation = hp_activation,\n",
    "                        input_dim = x_train.shape[-1]   \n",
    "                           )) \n",
    "    \n",
    "        # Tune whether to use dropout.\n",
    "        if hp.Boolean(\"Dropout 1\"):\n",
    "            model.add(layers.Dropout(rate=0.5))\n",
    "    \n",
    "        model.add(layers.Dense(units = hp_units_2, \n",
    "                            kernel_initializer = hp_kernel_initializer,    \n",
    "                            activation = hp_activation))\n",
    "            \n",
    "        if hp.Boolean(\"Dropout 2\"):\n",
    "            model.add(layers.Dropout(rate=0.5))\n",
    "            \n",
    "        model.add(layers.Dense(units = hp_units_3, \n",
    "                            kernel_initializer = hp_kernel_initializer,    \n",
    "                            activation = hp_activation))\n",
    "            \n",
    "        if hp.Boolean(\"Dropout 3\"):\n",
    "            model.add(layers.Dropout(rate=0.5))\n",
    "            \n",
    "        model.add(layers.Dense(units=1, \n",
    "                            kernel_initializer = hp_kernel_initializer,\n",
    "                            activation=\"sigmoid\"))\n",
    "            \n",
    "        if hp_loss == \"BC\":\n",
    "            with hp.conditional_scope(\"loss_type\", [\"BC\"]):\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                        loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                        metrics= [tf.keras.metrics.Accuracy(), tf.keras.metrics.AUC(), \n",
    "                                  tf.keras.metrics.Recall(), f1])\n",
    "        if hp_loss == \"FL\":\n",
    "            with hp.conditional_scope(\"loss_type\", [\"FL\"]):\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                        loss = tf.keras.losses.BinaryFocalCrossentropy(gamma = hp_gamma), \n",
    "                        metrics= [tf.keras.metrics.Accuracy(), tf.keras.metrics.AUC(), \n",
    "                                  tf.keras.metrics.Recall(), f1])\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x, y, validation_data=None, **kwargs):\n",
    "        hp_batch_size = hp.Choice(\"batch_size\", [16, 32, 64])\n",
    "        \n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            x = layers.Normalization()(x)\n",
    "        return model.fit(\n",
    "            x,\n",
    "            y,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            validation_data=validation_data,\n",
    "            batch_size = hp_batch_size,\n",
    "            class_weight = ClassWeights,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel = MyHyperModel(),\n",
    "    objective = kt.Objective(\"val_f1\", direction=\"max\"), \n",
    "    seed = SEED,\n",
    "    max_trials = 100,\n",
    "    overwrite=True,\n",
    "    directory = 'Deep_learning_project',\n",
    "    project_name = \"Default_predictions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200beb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train,\n",
    "             validation_data = (x_val, y_val),\n",
    "             epochs = 100,\n",
    "             verbose = 2,\n",
    "             initial_epoch = 0,\n",
    "             callbacks = CallBacksList,\n",
    "             use_multiprocessing = True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal hyper parameters are:\n",
    "The first layer: {best_hps.get(\"Layer 1\")}. \\n\n",
    "The second layer: {best_hps.get(\"Layer 2\")}. \\n\n",
    "The third layer: {best_hps.get(\"Layer 3\")}. \\n\n",
    "The activation function: {best_hps.get(\"activation\")}. \\n\n",
    "The kernel initializer: {best_hps.get(\"kernel_initializer\")}. \\n\n",
    "The loss function: {best_hps.get(\"loss_type\")}. \\n  \n",
    "The learning rate: {best_hps.get(\"learning_rate\")}. \\n\n",
    "The batch size: {best_hps.get(\"batch_size\")}. \\n\n",
    "Normalize the data: {best_hps.get(\"normalize\")}. \\n\n",
    "Dropout 1: {best_hps.get(\"Dropout 1\")}. \\n\n",
    "Dropout 2: {best_hps.get(\"Dropout 2\")}. \\n\n",
    "Dropout 3: {best_hps.get(\"Dropout 3\")}. \\n\n",
    "Shuffle: {best_hps.get(\"shuffle\")}. \\n\n",
    "Gamma: {best_hps.get(\"Gamma\")}. \\n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = MyHyperModel().build(best_hps)\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579eea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params.fit(\\x_train,\n",
    "            y_train,\n",
    "            epochs = 100,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle= True,\n",
    "            validation_data = (x_val, y_val),\n",
    "            batch_size = 64,\n",
    "            class_weight = ClassWeights,\n",
    "            callbacks = CallBacksList,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a973554",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_model_params.predict(x_train)\n",
    "y_pred_test = best_model_params.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28633294",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = (y_pred_train>0.5).astype(int)\n",
    "y_pred_test = (y_pred_test>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the confusion matrix\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['0', '1']\n",
    "make_confusion_matrix(cm, group_names=labels, categories=categories, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40233f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the classification report:\n",
    "\n",
    "TargetNames=[\"No Default\", \"Default\"]\n",
    "print(classification_report(y_test, y_pred_test, target_names = TargetNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the results performance.\n",
    "\n",
    "resultsDF = performanceMetricsDF(metrics, y_train, y_pred_train, y_test, y_pred_test)\n",
    "resultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE THE DIFFERENCE BETWENN THESE TWO MODELS ONE IS BUILT USING BEST_PARAMS,\n",
    "# AND ONE USING GET_BEST_PARAMS THIS IS A WIERD SITUATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dee889",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_model.predict(x_train)\n",
    "y_pred_test = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = (y_pred_train>0.5).astype(int)\n",
    "y_pred_test = (y_pred_test>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc304e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the confusion matrix\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['0', '1']\n",
    "make_confusion_matrix(cm, group_names=labels, categories=categories, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a582d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the classification report:\n",
    "\n",
    "TargetNames=[\"No Default\", \"Default\"]\n",
    "print(classification_report(y_test, y_pred_test, target_names = TargetNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the results performance.\n",
    "\n",
    "resultsDF = performanceMetricsDF(metrics, y_train, y_pred_train, y_test, y_pred_test)\n",
    "resultsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd62cc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff69c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t2 = time.perf_counter()\n",
    "print('Time taken to run in minutes:',(t2-t1)/60.0)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
